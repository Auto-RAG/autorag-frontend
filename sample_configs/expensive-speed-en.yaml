node_lines:
- node_line_name: retrieve_node_line  # Arbitrary node line name
  nodes:
    - node_type: retrieval
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        strategy: normalize_mean
        speed_threshold: 1
      top_k: 40
      modules:
        - module_type: bm25
        - module_type: vectordb
          vectordb: default
        - module_type: hybrid_rrf
          weight_range: (4,80)
        - module_type: hybrid_cc
          normalize_method: [ mm, tmm, z, dbsf ]
          weight_range: (0.0, 1.0)
          test_weight_size: 101
    - node_type: passage_augmenter
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        strategy: normalize_mean
        speed_threshold: 0.7
      top_k: 40
      embedding_model: openai
      modules:
        - module_type: pass_passage_augmenter
        - module_type: prev_next_augmenter
          mode: both
    - node_type: passage_reranker
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        speed_threshold: 2
      top_k: 5
      modules:
        - module_type: pass_reranker
        - module_type: cohere_reranker
        - module_type: jina_reranker
        - module_type: voyageai_reranker
        - module_type: mixedbreadai_reranker
    - node_type: passage_filter
      strategy:
        metrics: [ retrieval_f1, retrieval_recall, retrieval_precision,
                   retrieval_ndcg, retrieval_map, retrieval_mrr ]
        strategy: normalize_mean
        speed_threshold: 0.2
      modules:
        - module_type: pass_passage_filter
        - module_type: threshold_cutoff
          threshold: [0.85, 0.9, 0.95]
        - module_type: percentile_cutoff
          percentile: [0.6, 0.8]
- node_line_name: post_retrieve_node_line  # Arbitrary node line name
  nodes:
    - node_type: prompt_maker
      strategy:
        metrics:
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
          - metric_name: g_eval
        speed_threshold: 10
        strategy: normalize_mean
        generator_modules:
          - module_type: openai_llm
            llm: gpt-4o-mini
      modules:
        - module_type: fstring
          prompt: ["Tell me something about the question: {query} \n\n {retrieved_contents}",
                   "Question: {query} \n Something to read: {retrieved_contents} \n What's your answer?"]
        - module_type: long_context_reorder
          prompt: [ "Tell me something about the question: {query} \n\n {retrieved_contents}",
                    "Question: {query} \n Something to read: {retrieved_contents} \n What's your answer?" ]
    - node_type: generator
      strategy:
        metrics:
          - metric_name: meteor
          - metric_name: rouge
          - metric_name: sem_score
            embedding_model: openai
          - metric_name: g_eval  # LLM Judge Metric. Default Model: gpt-4-turbo
        speed_threshold: 10
        strategy: normalize_mean
      modules:
        - module_type: openai_llm
          llm: gpt-4o
          temperature: 1.0
